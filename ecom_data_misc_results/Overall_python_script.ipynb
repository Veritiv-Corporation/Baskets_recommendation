{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\liyenga\\AppData\\Local\\Temp\\ipykernel_6708\\1800087638.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "C:\\Users\\liyenga\\AppData\\Local\\Temp\\ipykernel_6708\\1800087638.py:2: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  all_sales_desc=pd.read_csv(\"all_sales_202401251719.csv\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "all_sales_desc=pd.read_csv(\"all_sales_202401251719.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for baskets grouping and product-wise association"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_avg_time_interval(row):\n",
    "    if row['so_key_frequency'] == 1:\n",
    "        return 1  # Set avg_time_interval = 1 for customers who ordered only 1 item\n",
    "    else:\n",
    "        return row['time_span_min_max'] / row['so_key_frequency']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_date_to_item_dict(row):\n",
    "    return dict(zip(row['invc_date'], row['item_cde']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "def create_baskets(row):\n",
    "    baskets = []\n",
    "    dates_items = row['invc_date_TO_item_cde']\n",
    "    avg_interval = row['avg_interval']\n",
    "\n",
    "    # Extract and sort the dates to ensure they are processed in chronological order\n",
    "    dates = sorted(dates_items.keys())\n",
    "    \n",
    "    i = 0\n",
    "    while i < len(dates):\n",
    "        current_date = dates[i]\n",
    "        current_basket = set(dates_items[current_date])  # Use a set to avoid duplicates\n",
    "        \n",
    "        # Calculate the end of the current interval\n",
    "        interval_end = current_date + timedelta(days=avg_interval)\n",
    "        \n",
    "        # Move to the next date to check if it falls within the current interval\n",
    "        i += 1\n",
    "        while i < len(dates) and dates[i] <= interval_end:\n",
    "            # Add items to the current basket since they are within the range\n",
    "            current_basket.update(dates_items[dates[i]])\n",
    "            i += 1  # Move to the next date\n",
    "        \n",
    "        # Add the current basket to the list of baskets, converting it back to a list\n",
    "        baskets.append(list(current_basket))\n",
    "    \n",
    "    return baskets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_baskets_365(row):\n",
    "    baskets = []\n",
    "    dates_items = row['invc_date_TO_item_cde']\n",
    "    avg_interval = round(row['avg_interval'])  # Round to nearest whole number\n",
    "\n",
    "    # Convert datetime dates to day of year (1-365)\n",
    "    day_to_items = {}\n",
    "    for date, items in dates_items.items():\n",
    "        day_of_year = date.timetuple().tm_yday\n",
    "        if day_of_year in day_to_items:\n",
    "            day_to_items[day_of_year].update(items)\n",
    "        else:\n",
    "            day_to_items[day_of_year] = set(items)\n",
    "\n",
    "    # Iterate through all 365 days\n",
    "    for day in range(1, 366):\n",
    "        if day in day_to_items:\n",
    "            current_basket = day_to_items[day]\n",
    "        else:\n",
    "            continue  # Skip days without purchases\n",
    "\n",
    "        # Look ahead within the interval, considering wrap around\n",
    "        for delta in range(1, avg_interval + 1):\n",
    "            next_day = (day + delta - 1) % 365 + 1  # Wrap around if exceeds 365\n",
    "            if next_day in day_to_items:\n",
    "                current_basket.update(day_to_items[next_day])\n",
    "\n",
    "        if current_basket:  # Only add non-empty baskets\n",
    "            baskets.append(list(current_basket))  # Converting it back to a list\n",
    "\n",
    "    return baskets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_items(item, rules): # given an item and association rules, generate recommendation\n",
    "    item_rules = rules[rules['antecedents'].apply(lambda x: item in set(x))]\n",
    "    recommended_items = item_rules['consequents'].explode().unique()\n",
    "    return recommended_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "def product_grouped_association(data,all_sales):\n",
    "\n",
    "    #Merege saLes data and Ecomm data\n",
    "    data_inter = pd.merge(data, all_sales, left_on='Item Number', right_on='item_cde')\n",
    "    data_inter['cat_old'] = data_inter['productcategory_1'] + '_' + data_inter['productcategory_2']\n",
    "    data_inter['cat'] = data_inter['cat_old']\n",
    "    data_inter.loc[~data_inter['productcategory_3'].isna(), 'cat'] += '_' +data_inter['productcategory_3']\n",
    "\n",
    "    #Groupby to gent day-wise baskets\n",
    "    billto_itemfrequency = data_inter.groupby(['bill_to', 'invc_date', 'item_cde', 'so_key']).agg({'qty_ship': 'sum'}).reset_index()\n",
    "    billto_itemfrequency['invc_date'] = pd.to_datetime(billto_itemfrequency['invc_date'])\n",
    "\n",
    "    billto_itemfrequency = billto_itemfrequency.groupby(['bill_to', 'invc_date']).agg(\n",
    "    item_cde=('item_cde', list),\n",
    "    so_key=('so_key', list),\n",
    "    qty_ship=('qty_ship', list),\n",
    "    so_key_frequency=('so_key', lambda x: len(set(x)))  # Count unique 'so_key' values\n",
    "    ).reset_index()\n",
    "\n",
    "    transactions_grpby_bill_to = billto_itemfrequency.groupby(['bill_to']).agg(\n",
    "    invc_date=('invc_date', list),\n",
    "    item_cde=('item_cde', list),\n",
    "    so_key=('so_key', list),\n",
    "    qty_ship=('qty_ship', list),\n",
    "    so_key_frequency=('so_key_frequency', 'sum')\n",
    "    ).reset_index()\n",
    "\n",
    "\n",
    "    #Find customer's average interval b/w purchases\n",
    "    transactions_grpby_bill_to['invc_date_TO_item_cde'] = transactions_grpby_bill_to.apply(create_date_to_item_dict, axis=1)\n",
    "\n",
    "    transactions_grpby_bill_to['time_span_min_max'] = transactions_grpby_bill_to['invc_date'].apply(lambda x: (max(x) - min(x)).days)\n",
    "    transactions_grpby_bill_to['avg_interval'] = transactions_grpby_bill_to.apply(calculate_avg_time_interval, axis=1)\n",
    "\n",
    "    transactions_grpby_bill_to['avg_interval'] = transactions_grpby_bill_to['avg_interval'].apply(lambda x: x if x >= 7 else 7)\n",
    "    transactions_basket = transactions_grpby_bill_to.copy()\n",
    "\n",
    "    # Create baskets using cyclic resampling to overcome non-uniform distribution issue\n",
    "    transactions_basket['baskets'] = transactions_basket.apply(create_baskets_365, axis=1)\n",
    "\n",
    "    flatten_basket_list=[item for sublist in list(transactions_basket['baskets']) for item in sublist]\n",
    "    te = TransactionEncoder()\n",
    "    te_ary = te.fit(flatten_basket_list).transform(flatten_basket_list)\n",
    "    df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "    # Use Apriori algorithm to find frequent itemsets\n",
    "    frequent_itemsets = apriori(df, min_support=0.0001, use_colnames=True)\n",
    "\n",
    "    # Generate association rules\n",
    "    rules = association_rules(frequent_itemsets, metric='confidence', min_threshold=0.5)\n",
    "\n",
    "    #Write the top 5 recommendation to the items dataframe\n",
    "    \n",
    "    all_3700_items=list(data['Item Number'])\n",
    "\n",
    "    all_recos=[]\n",
    "    all_recos_nonzero=[]\n",
    "    items=[]\n",
    "    \n",
    "    column_names=['Level','reco1', 'title1', 'reco2', 'title2', 'reco3', 'title3', 'reco4', 'title4', 'reco5', 'title5']\n",
    "\n",
    "    for col_name in column_names:\n",
    "        data[col_name] = None\n",
    "    \n",
    "    i=0\n",
    "    for ite in all_3700_items:\n",
    "        reco=recommend_items(ite, rules)\n",
    "        all_recos.append(reco)\n",
    "        if len(reco)>0:\n",
    "            items.append(ite)\n",
    "            j=1\n",
    "            data.loc[data['Item Number']==ite, 'Level'] = 'Product'\n",
    "            for r in reco:\n",
    "                if j<6:   # Limit to top 5 recommendations\n",
    "                    t=data.loc[data['Item Number'] == r, 'Product Title'].values[0]\n",
    "                    prod_col=f\"reco{j}\"\n",
    "                    tit_col=f\"title{j}\"\n",
    "                    reco_to_add= {prod_col: r, tit_col: t }\n",
    "\n",
    "                    for column, value in reco_to_add.items():\n",
    "                        data.loc[data['Item Number']==ite, column] = value\n",
    "                j+=1\n",
    "        \n",
    "            i+=1\n",
    "            all_recos_nonzero.append(reco)\n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for baskets combined cat association"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use daywise cat 3 level baskets to form association and write top 5 recommendations to the\n",
    "def combined_cat_association(df_inter,data):\n",
    "\n",
    "    bill_to_items = df_inter.groupby(['bill_to', 'invc_date','Category']).agg({'qty_ship': sum}).reset_index()\n",
    "    billto_items_qty= bill_to_items.groupby(['bill_to', 'invc_date']).agg({'Category': list,'qty_ship': list}).reset_index()\n",
    "    item_pairs=list(billto_items_qty['Category'])\n",
    "\n",
    "\n",
    "    te = TransactionEncoder()\n",
    "    te_ary = te.fit(item_pairs).transform(item_pairs)\n",
    "    df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "    frequent_itemsets = apriori(df, min_support=0.00005, use_colnames=True)\n",
    "    rules = association_rules(frequent_itemsets, metric='confidence', min_threshold=0.5)\n",
    "\n",
    "\n",
    "    all_cat=set(data['Category'])\n",
    "    i=0\n",
    "    for ite in all_cat:\n",
    "        reco=recommend_items(ite, rules)        \n",
    "        if len(reco)>0:\n",
    "              \n",
    "            data.loc[data['Item Number']==ite, 'Level'] = 'Cat3'\n",
    "            #m1=data['reco1'].isnull()\n",
    "            j=5\n",
    "            for r in reco:\n",
    "                if j>=1:\n",
    "                    prod_col=f\"reco{j}\"\n",
    "                    mask = (data['Category'] == ite) & (data['reco1'].isnull())\n",
    "                    data.loc[mask, prod_col] = r\n",
    "                j-=1        \n",
    "            i+=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for baskets cat1 association"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat1_association(df_inter,data):\n",
    "    bill_to_items = df_inter.groupby(['bill_to', 'invc_date','productcategory_1']).agg({'qty_ship': sum}).reset_index()\n",
    "    billto_items_qty= bill_to_items.groupby(['bill_to', 'invc_date']).agg({'productcategory_1': list,'qty_ship': list}).reset_index()\n",
    "    item_pairs=list(billto_items_qty['productcategory_1'])\n",
    "\n",
    "\n",
    "    te = TransactionEncoder()\n",
    "    te_ary = te.fit(item_pairs).transform(item_pairs)\n",
    "    df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "    frequent_itemsets = apriori(df, min_support=0.00005, use_colnames=True)\n",
    "    rules = association_rules(frequent_itemsets, metric='confidence', min_threshold=0.5)\n",
    "\n",
    "\n",
    "\n",
    "    all_cat=set(df_inter['productcategory_1'])\n",
    "    i=0\n",
    "    for ite in all_cat:\n",
    "        reco=recommend_items(ite, rules)        \n",
    "        if len(reco)>0:\n",
    "            data.loc[data['Item Number']==ite, 'Level'] = 'Cat1'\n",
    "            j=1\n",
    "            for r in reco:\n",
    "                if j<6:\n",
    "                    prod_col=f\"reco{j}\"\n",
    "                     \n",
    "                    mask = (df_inter['productcategory_1'] == ite) & (data['reco1'].isnull())  # Only taking the most associated cat.\n",
    "                    data.loc[mask, prod_col] = r\n",
    "                j+=1        \n",
    "            i+=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get items of interest custom input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ecom=pd.read_excel('test_category_column.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_ecom' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Create a copy of ecom items, in order to \u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m data_ecom1\u001b[38;5;241m=\u001b[39m\u001b[43mdata_ecom\u001b[49m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m      3\u001b[0m product_grouped_association(data_ecom1,all_sales_desc)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data_ecom' is not defined"
     ]
    }
   ],
   "source": [
    "#Create a copy of ecom items, in order to \n",
    "data_ecom1=data_ecom.copy()\n",
    "product_grouped_association(data_ecom1,all_sales_desc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Items with product level recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7       Wypall® X70 White Medium Duty Cloth (8.34 in. ...\n",
       "11      Oxivir® White Ready-To-Use Disinfectant Cleani...\n",
       "14                PURELL HEALTHY SOAP™ Gentle & Free Foam\n",
       "15      Ecolab® Clear Oxycide Daily Disinfectant Clean...\n",
       "18                PURELL HEALTHY SOAP™ Gentle & Free Foam\n",
       "                              ...                        \n",
       "3659    Reliable Brand® 1-Ply White Paper Hardwound To...\n",
       "3660    Reliable Brand® 2-Ply White Kitchen Paper Towe...\n",
       "3663    Reliable Brand® 2-Ply White Jumbo JRT Bath Tis...\n",
       "3665    Reliable Brand® 2-Ply White STD Bath Tissue Ro...\n",
       "3725    Fresh Products Orange 30-Day Wave Urinal Scree...\n",
       "Name: Product Title, Length: 379, dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_values = data_ecom1.loc[~data_ecom1['reco1'].isnull(), 'Product Title']\n",
    "filtered_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\liyenga\\AppData\\Local\\Temp\\ipykernel_6708\\156360095.py:4: FutureWarning: The provided callable <built-in function sum> is currently using SeriesGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  bill_to_items = df_inter.groupby(['bill_to', 'invc_date','Category']).agg({'qty_ship': sum}).reset_index()\n"
     ]
    }
   ],
   "source": [
    "#If any item has no recommendation, execute category-3 level association\n",
    "\n",
    "if data_ecom1['reco1'].isnull().any():\n",
    "    data_inter = pd.merge(data_ecom1, all_sales_desc, left_on='Item Number', right_on='item_cde')\n",
    "\n",
    "    combined_cat_association(data_inter,data_ecom1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Wypall® X70 White Medium Duty Cloth (14.875 in...\n",
       "1       Oxivir® TB White Disinfect Deodor Wipes (6 in....\n",
       "2       Wypall® White Wypall® X70 Hydroknit Wiper with...\n",
       "3       Oxivir® Clear Five Disinfectant Cleaner (1 gal...\n",
       "4       Oxivir® Clear Five Disinfectant Cleaner (84.5 ...\n",
       "                              ...                        \n",
       "3769    VGuard® Yellow Latex Flock Lined Chemical-Resi...\n",
       "3770    VGuard® Yellow Latex Flock Lined Chemical-Resi...\n",
       "3771    VGuard® 16-mil Yellow Latex Flock Lined Chemic...\n",
       "3772    VGuard® 13-mil Natural Latex Chemical-Resistan...\n",
       "3773    VGuard® 13-mil Natural Latex Chemical-Resistan...\n",
       "Name: Product Title, Length: 2920, dtype: object"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_values_2 = data_ecom1.loc[~data_ecom1['reco5'].isnull(), 'Product Title']\n",
    "filtered_values_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ecom1.to_csv('data_ecom_with_recos_1.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
